pipeline {
    agent any

    // Note: This pipeline requires Docker access. Ensure one of the following is configured:
    // 1. The Jenkins user has been added to the docker group: usermod -aG docker jenkins
    // 2. The Jenkins user has sudo access to run docker commands without password
    // 3. The Docker socket permissions have been modified: chmod 666 /var/run/docker.sock

    // Configure GitHub webhook trigger to monitor specific paths
    triggers {
        githubPush(
            // This will trigger the pipeline when changes are pushed to these paths
            includeBranches: ['main', 'master'],
            excludeBranches: [],
            includePaths: ['retraining_pipeline/**', 'src/model/**', 'data_pipeline/scripts/embeddings/**']
        )
    }

    environment {
        // Load credentials from env_variables.json
        MLFLOW_TRACKING_URI = credentials('MLFLOW_TRACKING_URI')
        GCP_PROJECT_ID = credentials('GCP_PROJECT_ID')
        GCP_BUCKET_NAME = credentials('GCP_BUCKET_NAME')
        GOOGLE_APPLICATION_CREDENTIALS = credentials('GOOGLE_APPLICATION_CREDENTIALS')
        EMAIL_ADDRESS = credentials('EMAIL_ADDRESS')

        // Additional environment variables
        ARTIFACT_REGISTRY_REPO = credentials('ARTIFACT_REGISTRY_REPO')
        WORKSPACE_DIR = "retraining_pipeline"
        MODEL_OUTPUT_DIR = "${WORKSPACE_DIR}/model_registry"
        DATA_DIR = "${WORKSPACE_DIR}/data"
    }

    stages {
        stage('Setup Python Environment') {
            steps {
                sh '''
                cd ${WORKSPACE_DIR}
                python3 -m venv venv
                . venv/bin/activate
                pip install --upgrade pip
                pip install -r requirements.txt
                '''
            }
        }

        stage('Download Data from GCS') {
            steps {
                sh '''
                cd ${WORKSPACE_DIR}
                . venv/bin/activate
                mkdir -p ${DATA_DIR}
                python download_from_gcs.py
                '''
            }
        }

        stage('Train Model') {
            steps {
                sh '''
                cd ${WORKSPACE_DIR}
                . venv/bin/activate
                mkdir -p ${MODEL_OUTPUT_DIR}
                python run_retraining.py
                '''
            }
        }

        stage('Build and Push Docker Image') {
            steps {
                withCredentials([file(credentialsId: 'GOOGLE_APPLICATION_CREDENTIALS', variable: 'GCP_KEY_FILE')]) {
                    sh '''
                    cd ${WORKSPACE_DIR}
                    . venv/bin/activate

                    # Use the GCP key file provided by Jenkins
                    export GOOGLE_APPLICATION_CREDENTIALS="${GCP_KEY_FILE}"

                    # Verify the file exists and is valid JSON
                    cat "${GOOGLE_APPLICATION_CREDENTIALS}" | jq . > /dev/null || echo "Warning: Credentials file is not valid JSON"

                    # Ensure Jenkins can run Docker commands with sudo
                    # This assumes the Jenkins user has been added to the sudoers file with NOPASSWD for docker commands
                    # If this fails, you'll need to configure sudoers on the Jenkins server
                    sudo -n true || echo "Warning: Jenkins user may not have sudo privileges without password"

                    python push_to_artifactory.py
                    '''
                }
            }
        }
    }

    post {
        success {
            emailext (
                subject: "Pipeline Success: ${currentBuild.fullDisplayName}",
                body: "The model retraining pipeline completed successfully. Check MLflow for model metrics.",
                to: "${EMAIL_ADDRESS}"
            )
        }
        failure {
            emailext (
                subject: "Pipeline Failed: ${currentBuild.fullDisplayName}",
                body: "The model retraining pipeline failed. Please check the Jenkins logs for details.",
                to: "${EMAIL_ADDRESS}"
            )
        }
    }
}
