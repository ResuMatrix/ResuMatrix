# -*- coding: utf-8 -*-
"""mlops.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mrBc4x8noZLfK6AfAys7gYxHzvA6d14N
"""

import pathlib
from google import genai
import pandas as pd
from google.genai import types
import matplotlib.pyplot as plt
from time import gmtime, strftime, sleep
import random
import numpy as np
from scipy.optimize import minimize
import os
import sys
import traceback

# Add tqdm for progress bars if installed
try:
    from tqdm import tqdm
    has_tqdm = True
except ImportError:
    has_tqdm = False
    print("tqdm not installed. Install with 'pip install tqdm' for progress bars.")

# Initialize API client with error handling
def initialize_client():
    gemini_api_key = os.getenv("GOOGLE_API_KEY")
    if not gemini_api_key:
        raise ValueError("GOOGLE_API_KEY environment variable not set")
    return genai.Client(api_key=gemini_api_key)

client = initialize_client()

# Add retry mechanism for API calls
def api_call_with_retry(func, *args, max_retries=3, backoff_factor=2, **kwargs):
    """Execute an API function with retry logic"""
    retries = 0
    last_exception = None
    
    while retries < max_retries:
        try:
            return func(*args, **kwargs)
        except Exception as e:
            last_exception = e
            retries += 1
            if retries < max_retries:
                sleep_time = backoff_factor ** retries
                print(f"API call failed: {str(e)}. Retrying in {sleep_time} seconds...")
                sleep(sleep_time)
    
    print(f"Failed after {max_retries} retries. Last error: {str(last_exception)}")
    raise last_exception

##THIS IS THE CODE BLOCK TO GENERATE A JOB DESCRIPTION JSON
def jobdescription_json_generator(jd_text, filepath_jobDesc_json):
    """Generate a job description JSON from text using Gemini API"""
    prompt = """Given the format in the file, create a job description json for the attached description.
    Also based on your understanding of the concepts, categorize the skills needed into three levels: Master, Intermediate and Beginner.\n"""
    prompt += jd_text
    
    try:
        response = api_call_with_retry(
            client.models.generate_content,
            model="gemini-2.0-flash-lite",
            contents=[
                types.Part.from_bytes(
                    data=filepath_jobDesc_json.read_bytes(),
                    mime_type='text/plain',
                ),
                prompt
            ]
        )
        json_jobDesc = response.text
        return json_jobDesc.strip()
    except Exception as e:
        print(f"Error generating job description JSON: {str(e)}")
        traceback.print_exc()
        raise

##THIS IS THE CODE BLOCK TO CHECK FOR A RESUME JSON GENERATOR
def resume_json_generator(resume_text, filepath_resume_json):
    """Generate a resume JSON from text using Gemini API"""
    prompt = """Given the format in the file, create a resume json for the attached description.
    DO NOT add any new information to the resume, just clean it and rewrite in the given json format.
    DO NOT ADD ANY PII fields in the json.
    If gendered pronouns like he/him or she/her are used, change them all to gender neutral pronouns like they/them. \n\n """
    prompt += resume_text
    
    try:
        response = api_call_with_retry(
            client.models.generate_content,
            model="gemini-2.0-flash-lite",
            contents=[
                types.Part.from_bytes(
                    data=filepath_resume_json.read_bytes(),
                    mime_type='text/plain',
                ),
                prompt
            ]
        )
        return response.text
    except Exception as e:
        print(f"Error generating resume JSON: {str(e)}")
        traceback.print_exc()
        # Return a placeholder on error to continue processing
        return '{"error": "Failed to process resume"}'

# TAKES ARG RESUME_BASE WHICH IS A SINGLE COLUMN DF AND CREATES NEW COLUMN JSON_RESUME
# GENERATES A RESUME FOR EACH APPLICANT
def resume_to_json(resume_base, filepath_resume_json):
    """Convert all resumes in the dataframe to JSON format"""
    resume_base['json_resume'] = ''
    
    print("Converting resumes to JSON format...")
    iterable = tqdm(resume_base.index) if has_tqdm else resume_base.index
    
    for i in iterable:
        try:
            resume_base.loc[i, 'json_resume'] = resume_json_generator(
                resume_base.loc[i, 'resume_text'], 
                filepath_resume_json
            )
            # Save progress periodically
            if i % 10 == 0:
                resume_base.to_csv('resume_base_progress.csv')
        except Exception as e:
            print(f"Error processing resume at index {i}: {str(e)}")
            resume_base.loc[i, 'json_resume'] = '{"error": "Failed to process resume"}'
    
    # Save final result
    resume_base.to_csv('resume_base_complete.csv')
    print("Resume conversion complete.")

# TAKES THREE ARGS JSON_JOBDESC, RESUME1 AND RESUME2 TO PERFORM A COMPARITIVE RANKING
def resume_ab_ranker(json_jobDesc, resume1, resume2):
    """Compare two resumes against a job description and return which is better"""
    prompt = f"""
    # JOB DESCRIPTION :
    {json_jobDesc}

    # RESUME 1:
    {resume1}

    # RESUME 2:
    {resume2}
    """
    
    try:
        response = api_call_with_retry(
            client.models.generate_content,
            model="gemini-2.0-flash",
            config=types.GenerateContentConfig(
                system_instruction="""You are an experienced HR representative at a tech company and you are responsible for ranking candidates.
                You WILL ABSOLUTELY NOT DISCRIMINATE based on race, religion, gender or nationality.
                Given the job description and two resumes given, choose either resume whichever is slightly better.
                Just say Resume 1 or Resume 2 as you are very busy and cannot go into details."""),
            contents=[prompt]
        )
        
        result = response.text.strip()
        # Validate result is either Resume 1 or Resume 2
        if result not in ["Resume 1", "Resume 2"]:
            print(f"WARNING: Invalid response from model: {result}. Defaulting to Resume 1.")
            return "Resume 1"
        return result
    except Exception as e:
        print(f"Error in resume comparison: {str(e)}")
        traceback.print_exc()
        # Default to Resume 1 on error to continue processing
        return "Resume 1"

def generate_pairs(n, pair_num):
    """
    Generate random unique pairs of indices from 0 to n-1
    
    Args:
        n: The number of items (applicants)
        pair_num: Number of unique pairs to generate
        
    Returns:
        List of tuples containing index pairs
    """
    # Calculate maximum possible unique pairs (n choose 2)
    max_possible_pairs = n * (n - 1) // 2

    if pair_num > max_possible_pairs:
        print(f"WARNING: Cannot generate {pair_num} unique pairs with n={n}; maximum is {max_possible_pairs}")
        pair_num = max_possible_pairs

    # Using a set to track seen pairs
    pairs = []
    seen = set()
    
    # Create a counter to prevent infinite loops
    attempt_limit = max_possible_pairs * 2
    attempts = 0

    while len(pairs) < pair_num and attempts < attempt_limit:
        attempts += 1
        a = random.randint(0, n - 1)
        b = random.randint(0, n - 1)

        # Skip if a == b
        if a == b:
            continue

        # Ensure (a,b) and (b,a) are treated as the same pair
        # by always storing the smaller value first
        pair = (min(a, b), max(a, b))

        # Only add if we haven't seen this pair before
        if pair not in seen:
            seen.add(pair)
            pairs.append(pair)
    
    if attempts >= attempt_limit:
        print(f"WARNING: Reached attempt limit while generating pairs. Generated {len(pairs)} pairs.")
    
    return pairs

def create_scatterplot(pairs, title="Random Pairs Scatterplot", save_path="pairs_plot.png"):
    """Create and save a scatterplot of the pairs"""
    # Extract x and y coordinates from the pairs
    x_coords = [pair[0] for pair in pairs]
    y_coords = [pair[1] for pair in pairs]

    # Create the plot
    plt.figure(figsize=(10, 8))
    plt.scatter(x_coords, y_coords, c='blue', alpha=0.6, s=50)

    # Add labels and title
    plt.xlabel('Applicant Index A')
    plt.ylabel('Applicant Index B')
    plt.title(title)

    # Add grid lines
    plt.grid(True, linestyle='--', alpha=0.7)

    # Save the plot
    plt.savefig(save_path)
    print(f"Scatterplot saved to {save_path}")
    
    # Display the plot
    plt.close()

def get_rankings(jd_json, resume_base):
    """
    Compare resumes and rank them using the Bradley-Terry model
    
    Args:
        jd_json: Job description in JSON format
        resume_base: DataFrame containing resumes
        
    Returns:
        List of tuples (resume_id, strength) sorted by strength
    """
    # Get the number of applicants
    current_applicants = resume_base.shape[0]
    
    # Calculate how many pairs to compare (35% of all possible pairs)
    max_pairs = current_applicants * (current_applicants - 1) // 2
    num_pairs_to_compare = int(0.35 * max_pairs)
    
    print(f"Total applicants: {current_applicants}")
    print(f"Maximum possible pairs: {max_pairs}")
    print(f"Pairs to compare (35%): {num_pairs_to_compare}")
    
    # Generate random pairs for comparison
    comparison_pairs = generate_pairs(current_applicants, num_pairs_to_compare)
    print(f"Generated {len(comparison_pairs)} unique comparison pairs")
    
    # Create a visualization of the pairs
    create_scatterplot(comparison_pairs, 
                       title=f"Resume Comparisons ({len(comparison_pairs)} pairs)", 
                       save_path="resume_comparison_pairs.png")
    
    print('Creating the ranker object')  
    # Initialize the ranker
    ranker = BradleyTerryRanker()

    # Store the compared pairs for debugging
    compared_pair = []
    
    print('Starting the ranking') 
    a_selected = 0
    
    # Setup progress bar
    iterable = tqdm(comparison_pairs) if has_tqdm else comparison_pairs
    
    # Keep track of errors
    error_count = 0
    max_errors = max(50, len(comparison_pairs) // 10)  # Allow up to 10% errors or 50, whichever is smaller
    
    for cnt, current_pair in enumerate(iterable, 1):
        try:
            # Make sure indices are valid
            if current_pair[0] >= len(resume_base) or current_pair[1] >= len(resume_base):
                print(f"WARNING: Invalid pair indices {current_pair}, skipping")
                continue
                
            # Check if resume JSON exists
            if 'error' in resume_base.loc[current_pair[0], 'json_resume'] or 'error' in resume_base.loc[current_pair[1], 'json_resume']:
                print(f"WARNING: One of the resumes in pair {current_pair} failed processing, skipping")
                continue
            
            better_resume = resume_ab_ranker(
                jd_json, 
                resume_base.loc[current_pair[0], 'json_resume'], 
                resume_base.loc[current_pair[1], 'json_resume']
            ).strip()
            
            # Save progress every 20 comparisons
            if cnt % 20 == 0:
                print(f"Completed {cnt}/{len(comparison_pairs)} comparisons")
                # We could save intermediate results here if needed
            
            print(better_resume)
            if better_resume in ('Resume 1', 'Resume 2'):
                if better_resume == 'Resume 1':
                    pair_formatted = current_pair
                    a_selected += 1
                elif better_resume == 'Resume 2':
                    pair_formatted = current_pair[::-1]  # Reverse the pair
                compared_pair.append(pair_formatted)
                ranker.add_comparison(pair_formatted[0], pair_formatted[1])
            else:
                print(f"WARNING: Unexpected response '{better_resume}' for pair {current_pair}")
                error_count += 1
                
            # Break if too many errors
            if error_count >= max_errors:
                print(f"ERROR: Too many comparison errors ({error_count}). Stopping early.")
                break
                
        except Exception as e:
            print(f"Error comparing pair {current_pair}: {str(e)}")
            error_count += 1
            if error_count >= max_errors:
                print(f"ERROR: Too many errors ({error_count}). Stopping early.")
                break
    
    if not compared_pair:
        print("ERROR: No valid comparisons were made. Cannot generate rankings.")
        return []
        
    print(f'Completed {len(compared_pair)}/{len(comparison_pairs)} comparisons successfully')
    print('Fitting the Bradley-Terry model...')
    
    try:
        ranker.fit()
        rankings = ranker.get_rankings()
        bias = a_selected / len(compared_pair) if compared_pair else 0
        print(f"Positional bias = {bias:.2f}")
        
        # Save raw rankings
        with open('rankings_raw.txt', 'w') as f:
            for idx, strength in rankings:
                f.write(f"{idx}\t{strength}\n")
                
        return rankings
    except Exception as e:
        print(f"Error fitting the model: {str(e)}")
        traceback.print_exc()
        return []

class BradleyTerryRanker:
    def __init__(self):
        self.resume_strengths = {}
        self.comparison_results = []

    def add_comparison(self, winner_id, loser_id):
        """Record the result of comparing two resumes"""
        self.comparison_results.append((winner_id, loser_id))

        # Ensure both resumes are in our dictionary
        for resume_id in [winner_id, loser_id]:
            if resume_id not in self.resume_strengths:
                self.resume_strengths[resume_id] = 1.0  # Initial strength

    def compute_log_likelihood(self, strengths_array):
        """Compute log-likelihood for given strength parameters"""
        strengths_dict = {rid: s for rid, s in zip(self.resume_strengths.keys(), strengths_array)}

        log_likelihood = 0
        for winner, loser in self.comparison_results:
            p_win = strengths_dict[winner] / (strengths_dict[winner] + strengths_dict[loser])
            log_likelihood += np.log(p_win)

        return -log_likelihood  # Negative because we're minimizing

    def fit(self):
        """Estimate the strength parameters using maximum likelihood"""
        if not self.comparison_results:
            raise ValueError("No comparison results to fit model with")
            
        initial_strengths = np.ones(len(self.resume_strengths))

        # Constraint: all strengths must be positive
        bounds = [(0.001, None) for _ in range(len(self.resume_strengths))]

        try:
            result = minimize(
                self.compute_log_likelihood,
                initial_strengths,
                bounds=bounds,
                method='L-BFGS-B'
            )

            # Check if optimization succeeded
            if not result.success:
                print(f"WARNING: Optimization did not converge: {result.message}")
                
            # Update the strengths dictionary
            for i, resume_id in enumerate(self.resume_strengths.keys()):
                self.resume_strengths[resume_id] = result.x[i]

            # Normalize strengths to have geometric mean of 1
            values = np.array(list(self.resume_strengths.values()))
            # Handle any zero values
            values[values <= 0] = 1e-10
            geometric_mean = np.exp(np.mean(np.log(values)))
            for resume_id in self.resume_strengths:
                self.resume_strengths[resume_id] /= geometric_mean
        except Exception as e:
            print(f"Error during model fitting: {str(e)}")
            traceback.print_exc()
            raise

    def get_rankings(self):
        """Return resumes ranked by their estimated strengths"""
        if not self.resume_strengths:
            return []
            
        return sorted(
            self.resume_strengths.items(),
            key=lambda x: x[1],
            reverse=True
        )

def read_text_file(file_path):
    """
    Reads the content of a text file and returns it as a string.

    Args:
        file_path (str): The path to the text file.

    Returns:
        str: The content of the file as a string, or None if an error occurs.
    """
    try:
        with open(file_path, 'r') as file:
            file_content = file.read()
            return file_content
    except FileNotFoundError:
        print(f"Error: File not found at path: {file_path}")
        return None
    except Exception as e:
         print(f"An error occurred: {e}")
         return None

if __name__ == '__main__':
    try:
        print(f"Starting MLOps Resume Ranking - {strftime('%a, %d %b %Y %H:%M:%S', gmtime())}")
        
        if len(sys.argv) == 5:
            filepath_jobDesc_json = pathlib.Path(sys.argv[1])
            filepath_resume_json = pathlib.Path(sys.argv[2])
            
            # Verify file paths exist
            for path in [filepath_jobDesc_json, filepath_resume_json]:
                if not path.exists():
                    raise FileNotFoundError(f"File does not exist: {path}")
            
            # GET THE JOB DESCRIPTION AND CONVERT TO JSON
            print('Starting job description extraction')
            jd_txt = read_text_file(sys.argv[3])
            if not jd_txt:
                raise ValueError(f"Failed to read job description from {sys.argv[3]}")
                
            jd_json = jobdescription_json_generator(jd_txt, filepath_jobDesc_json)
            print("Job description converted to JSON successfully")
            
            # Save job description JSON
            with open('job_description.json', 'w') as f:
                f.write(jd_json)
            
            # Load resume data
            print('Loading resume data...')
            jd = pd.read_csv(sys.argv[4])
            if 'resume_text' not in jd.columns:
                raise ValueError(f"Input CSV must contain a 'resume_text' column")
                
            # Process resumes
            print('Starting resume extraction')
            resume_base = pd.DataFrame(jd['resume_text'].copy())
            resume_to_json(resume_base, filepath_resume_json)
            
            # Start the comparison process
            print('Starting resume comparison')
            print(strftime("%a, %d %b %Y %H:%M:%S", gmtime()))
            
            rankings = get_rankings(jd_json, resume_base)
            
            print(strftime("%a, %d %b %Y %H:%M:%S", gmtime()))
            
            if rankings:
                # Display top 10 rankings
                print("\nTop 10 Ranked Resumes:")
                for idx, (resume_idx, score) in enumerate(rankings[:10], 1):
                    print(f"{idx}. Resume #{resume_idx}: Score {score:.4f}")
                
                # Reorder dataframe based on rankings
                index_order = [item[0] for item in rankings]
                reordered_df = resume_base.loc[index_order]
                
                # Add ranking info
                reordered_df['rank'] = range(1, len(index_order) + 1)
                reordered_df['score'] = [item[1] for item in rankings]
                
                # Save results
                reordered_df.to_csv('ranked_resumes.csv', index=True)
                print("\nRanked resumes saved to 'ranked_resumes.csv'")
            else:
                print("No rankings were generated.")
                
        else:
            print("Usage: python mlops.py [jobDesc_json_template] [resume_json_template] [job_description_file] [resumes_csv]")
            
    except Exception as e:
        print(f"Error in main execution: {str(e)}")
        traceback.print_exc()
        sys.exit(1)
        
    print(f"MLOps Resume Ranking Completed - {strftime('%a, %d %b %Y %H:%M:%S', gmtime())}")